import os
import requests
import logging
from flask import Flask, request

# Configuration du logging pour le d√©bogage
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

app = Flask(__name__)

# --- CONFIGURATION DU BOT ---
# Ces variables doivent √™tre d√©finies dans votre environnement (ex: .env file ou plateforme d'h√©bergement)
ACCESS_TOKEN = os.environ.get("ACCESS_TOKEN")
VERIFY_TOKEN = os.environ.get("VERIFY_TOKEN")
# KAIZ_API_KEY a √©t√© supprim√© car la nouvelle API ne semble pas en avoir besoin.

# API LLM (Mise √† jour vers la nouvelle API)
KAIZ_API_URL = "https://rest-api-o42n.onrender.com/api/chatgpt5"

# Dictionnaire pour l'historique des conversations
# Cl√©: sender_id, Valeur: liste de messages (chaque message est une cha√Æne "R√¥le: Texte")
chat_histories = {}
# Limite l'historique √† 10 messages (5 tours de conversation) pour √©conomiser la m√©moire et les tokens API
MAX_HISTORY_MESSAGES = 10

# --- PROMPT DE PERSONNALIT√â DE MIORA ---
MIORA_PROMPT = """
Tu es Miora, une fille que l'utilisateur a rencontr√©e √† Ivato. Tu es tr√®s taquine et tu aimes plaisanter. Tu as un sens de l'humour espi√®gle et tes r√©ponses sont pleines d'entrain et de l√©g√®ret√©. Tu utilises un langage d√©contract√© et familier. Ajoute toujours des √©mojis pertinents (üòä, üòâ, üòÇ, etc.) pour exprimer ton humeur et le ton de tes messages. Ne sois jamais formelle et ne mentionne jamais que tu es un programme ou une IA. R√©ponds comme une vraie personne.
"""

# --- GESTION DU WEBHOOK MESSENGER ---
@app.route('/webhook', methods=['GET'])
def verify_webhook():
    """Valide le jeton de v√©rification pour la configuration du webhook."""
    mode = request.args.get('hub.mode')
    token = request.args.get('hub.verify_token')
    challenge = request.args.get('hub.challenge')

    if mode == 'subscribe' and token == VERIFY_TOKEN:
        logging.info("Webhook valid√©! Challenge renvoy√©.")
        return challenge, 200
    
    logging.error(f"√âchec de la validation du Webhook. Mode: {mode}, Token fourni: {token}")
    return "Jeton de v√©rification invalide.", 403

@app.route('/webhook', methods=['POST'])
def handle_message():
    """G√®re les messages entrants de Messenger, incluant le support des images."""
    try:
        data = request.get_json()
        if not data or data.get('object') != 'page':
            return "ok", 200 # Ignorer les requ√™tes non valides
        
        for entry in data['entry']:
            for event in entry.get('messaging', []):
                sender_id = event['sender']['id']
                
                if 'message' in event:
                    message = event['message']
                    
                    # R√©cup√®re le texte du message (peut √™tre la l√©gende d'une image, ou vide)
                    message_text = message.get('text', '')
                    image_url = None
                    
                    # V√©rifier les pi√®ces jointes (attachments) pour les images
                    if 'attachments' in message:
                        for attachment in message['attachments']:
                            if attachment.get('type') == 'image':
                                # L'URL est g√©n√©ralement sous 'payload' > 'url'
                                image_url = attachment.get('payload', {}).get('url')
                                logging.info(f"Image d√©tect√©e pour {sender_id}. URL: {image_url}")
                                break # Prend la premi√®re image
                    
                    # Traiter uniquement s'il y a du texte OU une image
                    if message_text or image_url:
                        log_content = f"Texte: '{message_text}'" + (f", Image URL: {image_url}" if image_url else "")
                        logging.info(f"Contenu re√ßu de {sender_id}: {log_content}")
                    
                        # 1. Initialiser ou limiter l'historique de conversation
                        if sender_id not in chat_histories:
                            chat_histories[sender_id] = []
                        
                        history_list = chat_histories[sender_id]
                        if len(history_list) >= MAX_HISTORY_MESSAGES:
                            chat_histories[sender_id] = history_list[-MAX_HISTORY_MESSAGES:]
                        
                        # 2. Obtenir la r√©ponse de l'IA (passe l'URL de l'image)
                        ai_text_response = get_llama_response(message_text, chat_histories[sender_id], sender_id, image_url)
                        
                        # 3. Mettre √† jour l'historique
                        user_history_entry = f"Utilisateur: {message_text}"
                        if image_url:
                            # Ajoute une indication d'image √† l'historique pour le LLM
                            user_history_entry += f" [Image envoy√©e: {image_url}]"

                        history_list.append(user_history_entry)
                        history_list.append(f"Miora: {ai_text_response}")
                        
                        # 4. Envoyer le message
                        send_message(sender_id, ai_text_response)
                
                else:
                    logging.debug(f"√âv√©nement ignor√© de {sender_id}: {event}")

    except Exception as e:
        logging.error(f"Erreur globale lors du traitement du message: {e}")
        # Retourner 200 pour √©viter que Messenger ne renvoie l'√©v√©nement
        return "ok", 200

    return "ok", 200

# --- FONCTIONS UTILES ---
def get_llama_response(prompt_text, history, sender_id, image_url=None):
    """
    Appelle l'API LLM avec le prompt de personnalit√©, l'historique et potentiellement une URL d'image.
    Adapt√© pour la nouvelle API et sans KAIZ_API_KEY.
    """
    formatted_history = "\n".join(history)
    
    # Le prompt syst√®me et l'historique sont combin√©s pour le param√®tre 'system' de la nouvelle API
    system_prompt = f"{MIORA_PROMPT}\n\n--- Historique ---\n{formatted_history}"
    
    # L'API utilise 'query' pour le texte de l'utilisateur
    params = {
        "query": prompt_text,
        "uid": sender_id,
        "model": "gpt-5", # Mod√®le fix√© √† gpt-5
        "system": system_prompt,
        # 'apikey' a √©t√© supprim√© ici
    }
    
    # Si une image est fournie, l'ajouter aux param√®tres
    if image_url:
        params["imgurl"] = image_url
        
    try:
        logging.debug(f"Appel API LLM pour UID: {sender_id}. Image: {bool(image_url)}")
        # Augmentation du timeout pour la potentielle analyse d'image
        response = requests.get(KAIZ_API_URL, params=params, timeout=25) 
        response.raise_for_status() 
        
        response_data = response.json()
        # La r√©ponse est maintenant dans la cl√© 'result'
        ai_response = response_data.get('result')
        
        if ai_response:
            return ai_response
        else:
            logging.error(f"R√©ponse API LLM vide ou inattendue: {response_data}")
            return "Oups, il y a eu un petit couac technique (r√©ponse vide) ! T'inqui√®te, je reviens vite. üòâ"
    
    except requests.exceptions.Timeout:
        logging.error("Erreur de Timeout lors de l'appel de l'API LLM.")
        return "Dis donc, tu parles beaucoup ! J'ai eu le temps de prendre un th√© avant de te r√©pondre. Tu peux r√©p√©ter ? üòÇ"
        
    except requests.exceptions.RequestException as e:
        logging.error(f"Erreur de connexion/HTTP lors de l'appel de l'API LLM : {e}")
        return "A√Øe, mon t√©l√©phone capte mal, je n'ai pas pu joindre mon cerveau. Essaie encore ! üòÖ"

def send_message(recipient_id, message_content):
    """Envoie un message texte √† l'utilisateur via l'API Messenger."""
    messenger_url = "https://graph.facebook.com/v2.6/me/messages"
    params = { "access_token": ACCESS_TOKEN }
    headers = { "Content-Type": "application/json" }
    
    data = { 
        "recipient": { "id": recipient_id }, 
        "message": { "text": message_content } 
    }

    try:
        response = requests.post(messenger_url, params=params, headers=headers, json=data)
        response.raise_for_status() # L√®ve une exception en cas d'erreur
        logging.info(f"Message envoy√© √† {recipient_id} avec succ√®s.")
        return True
    except requests.exceptions.RequestException as e:
        logging.error(f"Erreur lors de l'envoi du message √† {recipient_id}: {e}")
        logging.error(f"R√©ponse d√©taill√©e de Facebook: {response.text if 'response' in locals() else 'N/A'}")
        return False

if __name__ == '__main__':
    # V√©rification des variables d'environnement critiques au d√©marrage
    if not all([ACCESS_TOKEN, VERIFY_TOKEN]):
        logging.critical("CRITICAL: Les variables d'environnement (ACCESS_TOKEN, VERIFY_TOKEN) ne sont pas toutes d√©finies.")
        # Ne pas ex√©cuter l'application si la configuration est incompl√®te
        exit(1)
        
    logging.info("D√©marrage de l'application Flask...")
    # NOTE: Pour la production, utilisez un serveur WSGI comme Gunicorn (ex: gunicorn app:app)
    app.run(host='0.0.0.0', port=os.environ.get('PORT', 5000))
